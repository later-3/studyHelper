"""
StudyHelper ä¸»åº”ç”¨ v2.0
é›†æˆè§’è‰²åŒ–ä»ªè¡¨ç›˜çš„ç”¨æˆ·ä½“éªŒå‡çº§ç‰ˆæœ¬
"""

import streamlit as st
from streamlit_option_menu import option_menu
from streamlit_lottie import st_lottie
import requests
import os
from PIL import Image
import json
import uuid
import re
from dotenv import load_dotenv
import logging
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core import logger_config

from typing import List, Dict
from datetime import datetime
import pandas as pd
from components.ui_components import (
    render_stats_overview, render_subject_distribution_chart, 
    render_activity_trend_chart, render_filter_panel,
    render_question_group_card, render_loading_spinner, render_empty_state, COLORS
)

# --- å¯¼å…¥è§’è‰²ä»ªè¡¨ç›˜ç»„ä»¶ ---
from components.student_dashboard import StudentDashboard
from components.teacher_dashboard import TeacherDashboard
from components.grade_manager_dashboard import GradeManagerDashboard
from components.principal_dashboard import PrincipalDashboard

# --- åˆå§‹åŒ–æ—¥å¿— ---
logger_config.setup_logging()
logger = logging.getLogger(__name__)

# --- åªä»æœåŠ¡å±‚å¯¼å…¥ --- 
from services import storage_service, ocr_service, llm_service
from services.data_service import data_service
from core import user_management_v2 as um

def load_lottieurl(url: str):
    """åŠ è½½LottieåŠ¨ç”»"""
    try:
        r = requests.get(url, timeout=5)
        if r.status_code != 200:
            logger.warning(f"Failed to fetch lottie animation from {url}, status code: {r.status_code}")
            return None
        return r.json()
    except requests.exceptions.RequestException:
        logger.error(f"Could not load Lottie animation from {url}", exc_info=True)
        return None

# --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ (å¯è¢«ç‹¬ç«‹æµ‹è¯•) ---
def intelligent_search_logic(user: dict, image_path: str, force_new_analysis: bool = False):
    """æ™ºèƒ½æœé¢˜æ ¸å¿ƒé€»è¾‘"""
    logger.info(f"Starting intelligent_search_logic for user {user['id']}. Image path: {image_path}, Force new: {force_new_analysis}")
    
    # é¦–å…ˆè¿›è¡ŒOCRè¯†åˆ«
    logger.info("Starting OCR process...")
    ocr_text_list = ocr_service.get_text_from_image(image_path)
    logger.info(f"OCRè¯†åˆ«ç»“æœ: {ocr_text_list}")
    ocr_text = '\n'.join(ocr_text_list)
    logger.info(f"OCRè¯†åˆ«å‡ºçš„æ–‡å­—å¦‚ä¸‹: {ocr_text}")
    
    # æ£€æŸ¥OCRç»“æœæ˜¯å¦æœ‰æ•ˆ
    if not ocr_text.strip() or ocr_text_list[0] in ["è¯†åˆ«å¤±è´¥", "è¯†åˆ«å¼‚å¸¸"]:
        logger.error(f"OCR failed for image: {image_path}, result: {ocr_text}")
        return None, "æ–‡å­—è¯†åˆ«å¤±è´¥æˆ–å›¾ç‰‡ä¸ºç©ºï¼Œè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ã€‚", None, None
    
    logger.info(f"OCR successful, text: {ocr_text[:100]}...")
    
    # å¦‚æœä¸æ˜¯å¼ºåˆ¶é‡æ–°åˆ†æï¼Œå°è¯•ä»ç¼“å­˜è·å–
    if not force_new_analysis:
        # L1ç¼“å­˜ï¼šé€šè¿‡å›¾ç‰‡phashæŸ¥æ‰¾
        existing_question = storage_service.get_question_by_phash(image_path)
        if existing_question and existing_question.get('master_analysis'):
            logger.info(f"L1 Cache HIT. Question ID: {existing_question['question_id']}")
            storage_service.save_submission(user['id'], existing_question['question_id'], "(Image match)")
            # è¿”å›æ–°OCRçš„ç»“æœï¼Œè€Œä¸æ˜¯å†å²æ•°æ®ä¸­çš„canonical_text
            return existing_question['master_analysis'], ocr_text, "phash_hit", existing_question['question_id']
        
        # L2ç¼“å­˜ï¼šé€šè¿‡æ–‡æœ¬hashæŸ¥æ‰¾
        question_id_from_text = storage_service.generate_question_id(ocr_text)
        existing_question = storage_service.get_question_by_id(question_id_from_text)
        if existing_question and existing_question.get('master_analysis'):
            logger.info(f"L2 Cache HIT based on text hash. Question ID: {question_id_from_text}")
            # å°†æ–°å›¾ç‰‡çš„phashå…³è”åˆ°ç°æœ‰é—®é¢˜
            storage_service.add_question(ocr_text, existing_question['master_analysis'], image_path, question_id_from_text)
            storage_service.save_submission(user['id'], question_id_from_text, ocr_text)
            return existing_question['master_analysis'], ocr_text, "text_hash_hit", question_id_from_text

    # ç¼“å­˜æœªå‘½ä¸­æˆ–å¼ºåˆ¶é‡æ–°åˆ†æï¼Œè°ƒç”¨å¤§æ¨¡å‹
    question_id_from_text = storage_service.generate_question_id(ocr_text)
    logger.info(f"Cache MISS or force new analysis. Calling LLM service for Question ID: {question_id_from_text}")
    
    analysis_str = llm_service.get_analysis_for_text(ocr_text)
    match = re.search(r'```json\n({[\s\S]*?})\n```', analysis_str)
    try:
        master_analysis = json.loads(match.group(1) if match else analysis_str)
    except json.JSONDecodeError:
        logger.error(f"Failed to parse LLM JSON response: {analysis_str}", exc_info=True)
        return None, f"AIåˆ†æç»“æœè§£æå¤±è´¥: {analysis_str}", None, None
    
    # ä¿å­˜æ–°çš„åˆ†æç»“æœ
    success = storage_service.add_question(ocr_text, master_analysis, image_path, question_id_from_text)
    if success:
        storage_service.save_submission(user['id'], question_id_from_text, ocr_text)
        logger.info(f"Successfully added new question to bank: {question_id_from_text}")
        cache_status = "miss"
    else:
        logger.error(f"Failed to save question data: {question_id_from_text}")
        return None, "ä¿å­˜åˆ†æç»“æœå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚", None, None
        
    return master_analysis, ocr_text, cache_status, question_id_from_text

# --- UI æ¸²æŸ“å‡½æ•° ---
def render_analysis_results(master_analysis, user, question_id, ocr_text):
    """æ¸²æŸ“AIåˆ†æç»“æœ"""
    st.subheader("ğŸ’¡ AIåˆ†æç»“æœ")
    if master_analysis.get("is_correct"):
        st.success("### æ­å–œä½ ï¼Œç­”å¯¹äº†ï¼ğŸ‰")
    else:
        st.error("### åˆ«ç°å¿ƒï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹é—®é¢˜å‡ºåœ¨å“ªï¼ŸğŸ¤”")
        if master_analysis.get("error_analysis"): st.markdown(f"**é”™è¯¯åˆ†æ:** {master_analysis['error_analysis']}")
        if master_analysis.get("correct_answer"): st.markdown(f"**æ­£ç¡®ç­”æ¡ˆ:** `{master_analysis['correct_answer']}`")
    
    past_submissions = storage_service.get_submissions_by_question(user['id'], question_id)
    if len(past_submissions) > 1:
        st.warning("âš ï¸ æ‚¨ä»¥å‰ä¹Ÿåšè¿‡è¿™é“é¢˜å“¦ï¼")
        for i, sub in enumerate(past_submissions[1:], 1):
            st.write(f"> ç¬¬{i}æ¬¡æäº¤äº: {sub['timestamp']}, å½“æ—¶æäº¤çš„å†…å®¹æ˜¯: `{sub['submitted_ocr_text']}`")

    st.markdown("---")
    with st.expander("âœ… è§£é¢˜æ­¥éª¤", expanded=True): st.info(master_analysis.get("solution_steps", "æš‚æ— æä¾›"))
    with st.expander("ğŸ§  æ ¸å¿ƒçŸ¥è¯†ç‚¹"): st.success(master_analysis.get("knowledge_point", "æš‚æ— æä¾›"))
    with st.expander("âš ï¸ å¸¸è§æ˜“é”™ç‚¹"): st.warning(master_analysis.get("common_mistakes", "æš‚æ— æä¾›"))

def intelligent_search_page():
    """æ™ºèƒ½æœé¢˜é¡µé¢"""
    st.title("ğŸ§  æ™ºèƒ½æœé¢˜")
    st.markdown("ä¸Šä¼ é¢˜ç›®ç…§ç‰‡ï¼ŒAIå¯¼å¸ˆå°†ä¸ºæ‚¨æä¾›ç‹¬å®¶åˆ†æã€‚å¦‚æœé¢˜ç›®å·²åœ¨æˆ‘ä»¬çš„çŸ¥è¯†åº“ä¸­ï¼Œæ‚¨å°†ç›´æ¥è·å¾—ç§’çº§å“åº”ï¼")

    if "analysis_results" not in st.session_state:
        st.session_state.analysis_results = None

    uploaded_file = st.file_uploader("æ”¯æŒ jpg, png, jpeg æ ¼å¼çš„å›¾ç‰‡", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None and uploaded_file.file_id != st.session_state.get('current_file_id'):
        st.session_state.current_file_id = uploaded_file.file_id
        st.session_state.analysis_results = None
        logger.info(f"New file uploaded: {uploaded_file.name}, File ID: {uploaded_file.file_id}")
        
        user = st.session_state.current_user
        if not user: st.error("å‘ç”Ÿé”™è¯¯ï¼šæ— æ³•è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œè¯·é‡æ–°ç™»å½•ã€‚"); return

        submission_dir = f"data/submissions/{user['id']}"
        os.makedirs(submission_dir, exist_ok=True)
        image_path = os.path.join(submission_dir, f"{uuid.uuid4().hex[:12]}.png")
        with open(image_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        logger.info(f"Image saved to persistent path: {image_path}")

        with st.spinner("ğŸ¤– AIå¯¼å¸ˆæ­£åœ¨åˆ†æä¸­...ï¼ˆé¦–æ¬¡åˆ†æå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰"):
            master_analysis, ocr_text, cache_status, question_id = intelligent_search_logic(user, image_path)
        
        st.session_state.analysis_results = {
            "master_analysis": master_analysis,
            "ocr_text": ocr_text,
            "cache_status": cache_status,
            "question_id": question_id,
            "image_path": image_path
        }

    if st.session_state.analysis_results:
        res = st.session_state.analysis_results
        master_analysis = res['master_analysis']
        ocr_text = res['ocr_text']
        cache_status = res['cache_status']
        question_id = res['question_id']
        image_path = res['image_path']
        user = st.session_state.current_user

        if not master_analysis:
            st.error(ocr_text)
            return

        col1, col2 = st.columns(2)
        with col1: st.image(image_path, caption="æ‚¨ä¸Šä¼ çš„é¢˜ç›®", use_container_width=True)
        with col2:
            if cache_status == 'phash_hit':
                st.success("âš¡ï¸ å›¾ç‰‡å·²è¯†åˆ«ï¼æˆ‘ä»¬ä»¥å‰è§è¿‡è¿™å¼ å›¾ã€‚")
                st.info("ç›´æ¥ä¸ºæ‚¨å±•ç¤ºå†å²åˆ†æç»“æœã€‚")
            elif cache_status == 'text_hash_hit':
                st.success("âš¡ï¸ é¢˜ç›®å†…å®¹å·²è¯†åˆ«ï¼")
                st.info("è™½ç„¶å›¾ç‰‡æ˜¯æ–°çš„ï¼Œä½†æˆ‘ä»¬åšè¿‡è¿™é“é¢˜ã€‚")
            else:
                st.info("âœ¨ å…¨æ–°é¢˜ç›®ï¼å·²ä¸ºæ‚¨æ°¸ä¹…å­˜å…¥çŸ¥è¯†åº“ï¼")
            
            st.text_area("è¯†åˆ«å‡ºçš„æ–‡å­—å¦‚ä¸‹ï¼š", ocr_text, height=100)
            logger.info(f"è¯†åˆ«å‡ºçš„æ–‡å­—å¦‚ä¸‹ï¼š{ocr_text}")

        if st.button("å¼ºåˆ¶ä½¿ç”¨å¤§æ¨¡å‹é‡æ–°åˆ†æ", help="å¦‚æœæ‚¨è®¤ä¸ºAIçš„åˆ†æç»“æœä¸å¤Ÿç†æƒ³ï¼Œå¯ä»¥å¼ºåˆ¶ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œä¸€æ¬¡å…¨æ–°çš„åˆ†æ"):
            with st.spinner("ğŸ¤– æ­£åœ¨å¼ºåˆ¶è°ƒç”¨å¤§æ¨¡å‹...è¯·ç¨å€™"):
                master_analysis, ocr_text, cache_status, question_id = intelligent_search_logic(user, image_path, force_new_analysis=True)
            st.session_state.analysis_results['master_analysis'] = master_analysis
            st.success("âœ… å·²è·å–æœ€æ–°çš„AIåˆ†æç»“æœï¼")
            st.rerun()

        render_analysis_results(master_analysis, user, question_id, ocr_text)

def home():
    """é¦–é¡µ"""
    st.title("ğŸ  StudyHelper æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹")
    
    # åŠ è½½åŠ¨ç”»
    lottie_url = "https://assets5.lottiefiles.com/packages/lf20_xyadoh9h.json"
    lottie_json = load_lottieurl(lottie_url)
    
    if lottie_json:
        col1, col2 = st.columns([1, 2])
        with col1:
            st_lottie(lottie_json, height=300, key="home_animation")
        with col2:
            st.markdown("""
            ## ğŸ¯ æ¬¢è¿ä½¿ç”¨ StudyHelperï¼
            
            **StudyHelper** æ˜¯ä¸€æ¬¾åŸºäºAIçš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ï¼Œæ—¨åœ¨ä¸ºå­¦ç”Ÿã€æ•™å¸ˆå’Œç®¡ç†è€…æä¾›å…¨æ–¹ä½çš„æ•™è‚²æ”¯æŒã€‚
            
            ### âœ¨ æ ¸å¿ƒåŠŸèƒ½
            - ğŸ§  **æ™ºèƒ½æœé¢˜**: AIåˆ†æé¢˜ç›®ï¼Œæä¾›è¯¦ç»†è§£ç­”
            - ğŸ“Š **å­¦ä¹ åˆ†æ**: æ·±åº¦åˆ†æå­¦ä¹ æ•°æ®ï¼Œå‘ç°è–„å¼±ç¯èŠ‚
            - ğŸ‘¥ **è§’è‰²ç®¡ç†**: æ”¯æŒå­¦ç”Ÿã€æ•™å¸ˆã€å¹´çº§ä¸»ä»»ã€æ ¡é•¿å¤šè§’è‰²
            - ğŸ“ˆ **è¿›åº¦è·Ÿè¸ª**: å®æ—¶ç›‘æ§å­¦ä¹ è¿›åº¦å’Œè¡¨ç°
            
            ### ğŸ“ é€‚ç”¨äººç¾¤
            - **å­¦ç”Ÿ**: æ™ºèƒ½è§£é¢˜ã€é”™é¢˜ç®¡ç†ã€å­¦ä¹ å»ºè®®
            - **æ•™å¸ˆ**: ç­çº§ç®¡ç†ã€å­¦ç”Ÿåˆ†æã€æ•™å­¦æŒ‡å¯¼
            - **å¹´çº§ä¸»ä»»**: å¹´çº§ç®¡ç†ã€æ•™å¸ˆè¯„ä¼°ã€æ•°æ®åˆ†æ
            - **æ ¡é•¿**: å­¦æ ¡ç®¡ç†ã€æˆ˜ç•¥å†³ç­–ã€æ•´ä½“è§„åˆ’
            """)
    else:
        st.markdown("""
        ## ğŸ¯ æ¬¢è¿ä½¿ç”¨ StudyHelperï¼
        
        **StudyHelper** æ˜¯ä¸€æ¬¾åŸºäºAIçš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ï¼Œæ—¨åœ¨ä¸ºå­¦ç”Ÿã€æ•™å¸ˆå’Œç®¡ç†è€…æä¾›å…¨æ–¹ä½çš„æ•™è‚²æ”¯æŒã€‚
        """)

def submission_history_page():
    """ç­”é¢˜å†å²é¡µé¢"""
    st.title("ğŸ“š ç­”é¢˜å†å²")
    user = st.session_state.current_user
    if not user: st.warning("è¯·å…ˆç™»å½•ä»¥æŸ¥çœ‹æ­¤é¡µé¢ã€‚"); return

    # è·å–ç”¨æˆ·æäº¤å†å²
    submissions = storage_service.get_submissions_by_user(user['id'])
    if not submissions:
        st.info("æ‚¨è¿˜æ²¡æœ‰æäº¤è¿‡ä»»ä½•é¢˜ç›®ã€‚")
        return

    # è§†å›¾é€‰æ‹©
    view_options = ["åˆ†ç»„è§†å›¾", "æ—¶é—´çº¿è§†å›¾", "ç»Ÿè®¡è§†å›¾"]
    selected_view = st.radio("é€‰æ‹©æŸ¥çœ‹æ–¹å¼", view_options, horizontal=True)

    if selected_view == "åˆ†ç»„è§†å›¾":
        render_grouped_view(submissions)
    elif selected_view == "æ—¶é—´çº¿è§†å›¾":
        render_timeline_view(submissions)
    else:
        render_stats_view(submissions)

def render_grouped_view(submissions: List[Dict]):
    """æ¸²æŸ“åˆ†ç»„è§†å›¾"""
    st.subheader("ğŸ“Š åˆ†ç»„è§†å›¾")
    
    # è·å–è¯¦ç»†ç»Ÿè®¡
    stats = data_service.get_submission_stats(submissions)
    
    # æ˜¾ç¤ºæ¦‚è§ˆç»Ÿè®¡
    render_stats_overview(stats)
    
    # å­¦ç§‘åˆ†å¸ƒå›¾è¡¨
    if stats['subject_distribution']:
        render_subject_distribution_chart(stats['subject_distribution'])
    
    # æ´»åŠ¨è¶‹åŠ¿å›¾è¡¨
    if stats['recent_activity']:
        render_activity_trend_chart(stats['recent_activity'])
    
    # æŒ‰å­¦ç§‘åˆ†ç»„æ˜¾ç¤ºé¢˜ç›®
    if stats['subject_distribution']:
        for subject in stats['subject_distribution'].keys():
            subject_submissions = [s for s in submissions if 
                                 (s.get('ai_analysis', {}).get('subject') == subject) or
                                 (data_service.get_question_details(s.get('question_id', '')) or {}).get('subject') == subject]
            
            if subject_submissions:
                render_question_group_card(subject, subject_submissions)

def render_timeline_view(submissions: List[Dict]):
    """æ¸²æŸ“æ—¶é—´çº¿è§†å›¾"""
    st.subheader("â° æ—¶é—´çº¿è§†å›¾")
    
    # æŒ‰æ—¶é—´æ’åº
    sorted_submissions = sorted(submissions, key=lambda x: x.get('timestamp', ''), reverse=True)
    
    for submission in sorted_submissions:
        # è·å–é¢˜ç›®è¯¦æƒ…
        question_details = data_service.get_question_details(submission.get('question_id', ''))
        ai_analysis = submission.get('ai_analysis', {})
        
        # ç¡®å®šå­¦ç§‘
        subject = (ai_analysis.get('subject') or 
                  question_details.get('subject') or 
                  "æœªçŸ¥å­¦ç§‘")
        
        # ç¡®å®šæ˜¯å¦æ­£ç¡®
        is_correct = (ai_analysis.get('is_correct') or 
                     question_details.get('master_analysis', {}).get('is_correct'))
        
        # è·å–é¢˜ç›®æ–‡æœ¬
        q_text = (submission.get('submitted_ocr_text', '') or 
                 question_details.get('canonical_text', '') or 
                 "é¢˜ç›®å†…å®¹æœªçŸ¥")
        
        # æ ¼å¼åŒ–æ—¶é—´
        timestamp = submission.get('timestamp', '')
        if timestamp:
            try:
                date = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                time_str = date.strftime('%H:%M')
            except:
                time_str = timestamp
        else:
            time_str = 'æœªçŸ¥æ—¶é—´'
        
        # çŠ¶æ€å›¾æ ‡
        status_icon = "âœ…" if is_correct is True else "âŒ" if is_correct is False else "â“"
        
        # æ˜¾ç¤ºä¿¡æ¯
        col1, col2, col3, col4 = st.columns([1, 1, 2, 6])
        with col1:
            st.write(time_str)
        with col2:
            st.write(status_icon)
        with col3:
            st.write(f"**{subject}**")
        with col4:
            st.write(q_text[:50] + "..." if len(q_text) > 50 else q_text)
        
        st.divider()

def render_stats_view(submissions: List[Dict]):
    """æ¸²æŸ“ç»Ÿè®¡è§†å›¾"""
    st.subheader("ğŸ“Š è¯¦ç»†ç»Ÿè®¡")
    
    # è·å–è¯¦ç»†ç»Ÿè®¡
    stats = data_service.get_submission_stats(submissions)
    
    # å­¦ç§‘è¯¦ç»†ç»Ÿè®¡
    st.write("### å­¦ç§‘è¡¨ç°")
    if stats['subject_distribution']:
        subject_data = []
        for subject, count in stats['subject_distribution'].items():
            # è®¡ç®—è¯¥å­¦ç§‘çš„æ­£ç¡®ç‡
            subject_submissions = [s for s in submissions if 
                                 (s.get('ai_analysis', {}).get('subject') == subject) or
                                 (data_service.get_question_details(s.get('question_id', '')) or {}).get('subject') == subject]
            
            correct_count = sum(1 for s in subject_submissions if 
                              (s.get('ai_analysis', {}).get('is_correct') is True) or
                              (data_service.get_question_details(s.get('question_id', '')) or {}).get('master_analysis', {}).get('is_correct') is True)
            
            accuracy = (correct_count / count * 100) if count > 0 else 0
            subject_data.append({
                'å­¦ç§‘': subject,
                'é¢˜æ•°': count,
                'æ­£ç¡®æ•°': correct_count,
                'æ­£ç¡®ç‡': f"{accuracy:.1f}%"
            })
        
        # æ˜¾ç¤ºè¡¨æ ¼
        df = pd.DataFrame(subject_data)
        st.dataframe(df, use_container_width=True)
    
    # æœ€è¿‘æ´»åŠ¨è¯¦ç»†ç»Ÿè®¡
    st.write("### æœ€è¿‘æ´»åŠ¨")
    if stats['recent_activity']:
        activity_data = []
        for date, count in sorted(stats['recent_activity'].items()):
            activity_data.append({
                'æ—¥æœŸ': date,
                'æäº¤æ¬¡æ•°': count
            })
        
        df = pd.DataFrame(activity_data)
        st.dataframe(df, use_container_width=True)

def about():
    """å…³äºé¡µé¢"""
    st.title("â„¹ï¸ å…³äº StudyHelper")
    st.info(
        """
        **ç‰ˆæœ¬:** 2.0.0 (è§’è‰²åŒ–ç”¨æˆ·ä½“éªŒå‡çº§ç‰ˆ)
        **é¡¹ç›®æ„¿æ™¯:** æ‰“é€ ä¸€æ¬¾æ‡‚ä½ çš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ã€‚
        
        ### ğŸ†• æ–°åŠŸèƒ½
        - è§’è‰²åŒ–ä»ªè¡¨ç›˜ï¼šå­¦ç”Ÿã€æ•™å¸ˆã€å¹´çº§ä¸»ä»»ã€æ ¡é•¿ä¸“å±ç•Œé¢
        - æ™ºèƒ½æ•°æ®åˆ†æï¼šåŸºäºè§’è‰²çš„ä¸ªæ€§åŒ–æ•°æ®å±•ç¤º
        - ç”¨æˆ·ä½“éªŒä¼˜åŒ–ï¼šç®€æ´ç¾è§‚çš„ç•Œé¢è®¾è®¡
        
        ### ğŸ¯ æŠ€æœ¯ç‰¹è‰²
        - AIé©±åŠ¨çš„æ™ºèƒ½åˆ†æ
        - æ¨¡å—åŒ–ç»„ä»¶è®¾è®¡
        - å®Œæ•´çš„æµ‹è¯•è¦†ç›–
        - å“åº”å¼ç”¨æˆ·ç•Œé¢
        """
    )

def role_dashboard_page():
    """è§’è‰²ä»ªè¡¨ç›˜é¡µé¢"""
    user = st.session_state.current_user
    if not user: 
        st.warning("è¯·å…ˆç™»å½•ä»¥æŸ¥çœ‹æ­¤é¡µé¢ã€‚")
        return
    
    # æ ¹æ®ç”¨æˆ·è§’è‰²æ˜¾ç¤ºå¯¹åº”çš„ä»ªè¡¨ç›˜
    role = user['role']
    
    if role == 'student':
        st.title("ğŸ“ å­¦ç”Ÿä»ªè¡¨ç›˜")
        student_dashboard = StudentDashboard()
        student_dashboard.render_student_dashboard(user['id'])
        
    elif role == 'teacher':
        st.title("ğŸ‘¨â€ğŸ« æ•™å¸ˆä»ªè¡¨ç›˜")
        teacher_dashboard = TeacherDashboard()
        teacher_dashboard.render_teacher_dashboard(user['id'])
        
    elif role == 'grade_manager':
        st.title("ğŸ‘¨â€ğŸ’¼ å¹´çº§ä¸»ä»»ä»ªè¡¨ç›˜")
        grade_manager_dashboard = GradeManagerDashboard()
        grade_manager_dashboard.render_grade_manager_dashboard(user['id'])
        
    elif role == 'principal':
        st.title("ğŸ« æ ¡é•¿ä»ªè¡¨ç›˜")
        principal_dashboard = PrincipalDashboard()
        principal_dashboard.render_principal_dashboard(user['id'])
        
    else:
        st.error(f"æœªçŸ¥çš„ç”¨æˆ·è§’è‰²: {role}")

# --- ä¸»ç¨‹åº ---
load_dotenv("/Users/xulater/studyHelper/studyhelper-demo/studyhelper-demo-final/.env")
st.set_page_config(page_title="StudyHelper v2.0", page_icon="ğŸ“˜", layout="wide")

if 'current_user' not in st.session_state: 
    st.session_state.current_user = None

with st.sidebar:
    if st.session_state.current_user:
        user = st.session_state.current_user
        role_icon = {
            "student": "ğŸ“", 
            "teacher": "ğŸ‘¨â€ğŸ«", 
            "grade_manager": "ğŸ“Š", 
            "principal": "ğŸ«"
        }
        
        # ç”¨æˆ·ä¿¡æ¯å¡ç‰‡
        st.markdown(f"### {role_icon.get(user['role'], 'ğŸ‘¤')} {user['name']}")
        st.markdown(f"**è§’è‰²**: {user['role']}")
        st.markdown("---")
        
        if st.button("é€€å‡ºç™»å½•", use_container_width=True, type="primary"): 
            st.session_state.current_file_id = None
            st.session_state.analysis_results = None
            st.session_state.current_user = None
            st.rerun()
    else:
        st.info("è¯·é€‰æ‹©ç”¨æˆ·ç™»å½•")
        users = um.get_all_users()
        user_options = {user['id']: f"{user['name']} ({user['role']})" for user in users}
        selected_user_id = st.selectbox("é€‰æ‹©ç”¨æˆ·", options=list(user_options.keys()), format_func=lambda x: user_options[x], index=None, placeholder="è¯·é€‰æ‹©...")
        if st.button("ç™»å½•", use_container_width=True):
            if selected_user_id: 
                st.session_state.current_user = um.get_user_by_id(selected_user_id)
                st.session_state.analysis_results = None
                st.rerun()
            else: 
                st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªç”¨æˆ·")
        st.markdown("---")

    # åŠ¨æ€èœå•é€‰é¡¹
    options = ["é¦–é¡µ", "å…³äº"]
    icons = ["house", "info-circle"]
    
    if st.session_state.current_user:
        # æ·»åŠ è§’è‰²ä»ªè¡¨ç›˜
        options.insert(1, "ä»ªè¡¨ç›˜")
        icons.insert(1, "speedometer")
        
        # æ ¹æ®è§’è‰²æ·»åŠ åŠŸèƒ½é€‰é¡¹
        if st.session_state.current_user['role'] in ['student', 'teacher', 'grade_manager', 'principal']:
            options.insert(2, "ç­”é¢˜å†å²")
            icons.insert(2, "card-checklist")
        
        if st.session_state.current_user['role'] in ['student', 'teacher']:
            options.insert(2, "æ™ºèƒ½æœé¢˜")
            icons.insert(2, "search")

    selected = option_menu(
        menu_title="StudyHelper v2.0", 
        options=options, 
        icons=icons, 
        menu_icon="book", 
        default_index=0,
        styles={
            "container": {"padding": "5!important", "background-color": "#fafafa"},
            "icon": {"color": "orange", "font-size": "18px"}, 
            "nav-link": {"color": "#333333", "font-size": "14px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
            "nav-link-selected": {"background-color": "#02ab21"},
        }
    )

# é¡µé¢è·¯ç”±
if selected == "é¦–é¡µ": 
    home()
elif selected == "ä»ªè¡¨ç›˜": 
    role_dashboard_page()
elif selected == "æ™ºèƒ½æœé¢˜":
    if st.session_state.current_user: 
        intelligent_search_page()
    else: 
        st.warning("è¯·ä»ä¾§è¾¹æ ç™»å½•ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
elif selected == "ç­”é¢˜å†å²":
    if st.session_state.current_user: 
        submission_history_page()
    else: 
        st.warning("è¯·ä»ä¾§è¾¹æ ç™»å½•ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
elif selected == "å…³äº": 
    about() 